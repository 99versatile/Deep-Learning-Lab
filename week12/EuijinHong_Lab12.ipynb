{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upEJK8UUDnyn"
   },
   "source": [
    "> ### EEE4423: Deep Learning Lab\n",
    "\n",
    "# LAB \\#12: Sequence to Sequence Network with Attention Module\n",
    "## Machine Translation with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAv1aaG8Dnys"
   },
   "source": [
    "<h4><div style=\"text-align: right\"> Due date: May 27, 2022. </div> <br>\n",
    "<div style=\"text-align: right\"> Please upload your file @ LearnUs by 9 AM in the form of [ID_Name_Lab12.ipynb]. </div></h4>\n",
    "\n",
    "### *Instructions:*\n",
    "- Write a program implementing a particular algorithm to solve a given problem.   \n",
    "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span> \n",
    "- Each team must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SULIl9bRDnys"
   },
   "source": [
    "<h2><span style=\"color:blue\">[2018142102] [Euijin Hong]</span> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "2JP0LD9nDnys",
    "outputId": "0c1a8aae-4843-435b-dbaa-9624d918ff03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2023-05-25 14:57:20.766102\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBvC_gonDnyu"
   },
   "source": [
    "In this project we will be teaching a neural network to translate from\n",
    "French to English.\n",
    "*************************************************************\n",
    "::\n",
    "\n",
    "    [(>): input, (=): target, (<): output]\n",
    "\n",
    "    > il est en train de peindre un tableau .\n",
    "    = he is painting a picture .\n",
    "    < he is painting a picture .\n",
    "\n",
    "    > pourquoi ne pas essayer ce vin delicieux ?\n",
    "    = why not try that delicious wine ?\n",
    "    < why not try that delicious wine ?\n",
    "\n",
    "    > elle n est pas poete mais romanciere .\n",
    "    = she is not a poet but a novelist .\n",
    "    < she not not a poet but a novelist .\n",
    "\n",
    "    > vous etes trop maigre .\n",
    "    = you re too skinny .\n",
    "    < you re all alone .\n",
    "\n",
    "...\n",
    "*************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nLSIcUoZDnyu"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v0s8XW7Dnyv"
   },
   "source": [
    "### 1. Prepare data\n",
    "\n",
    "The data for this project is a set of many thousands of English to French translation pairs. Download the data from <https://download.pytorch.org/tutorial/data.zip>. The file is a tab separated list of translation pairs:\n",
    "\n",
    "\n",
    "    I am cold.    J'ai froid.\n",
    "    \n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1K3W2RxeTKih5IiT5PcIyWNZSwMqtYSGZ\"  onerror=\"this.style.display='none'\" style=\"width: 600px;\"/><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Xn2soUCGDnyv",
    "outputId": "a76ed812-6017-4ceb-a52c-2fd70a6b1377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counted words: fra = 4345 eng = 2803\n",
      "['tu me fais marrer .', 'you re amusing .']\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10 # limit the sentence length\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \")\n",
    "\n",
    "class Lang: # mapping to numbers for each language, frn and eng respectively\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    # Read the file and split into lines\n",
    "    lines = open('./dataset-dllab/lab12/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\", input_lang.name, '=', input_lang.n_words, output_lang.name, '=', output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "A8yVC59WDnyw"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4qXkB3DDnyw"
   },
   "source": [
    "### 2. Build the Seq2Seq model [5 points]\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1kKXrIIxi0t-Nm5HfzOukqjzEp7yEXEpV\"  onerror=\"this.style.display='none'\" /><br><br>\n",
    "\n",
    "[sequence to sequence network](https://arxiv.org/abs/1409.3215) is a model in which two\n",
    "recurrent neural networks work together to transform one sequence to\n",
    "another. An encoder network condenses an input sequence into a single vector,\n",
    "and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input\n",
    "corresponds to an output, the seq2seq model frees us from sequence\n",
    "length and order, which makes it ideal for translation between two\n",
    "languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDTwMr5TDnyy"
   },
   "source": [
    "#### Encoder\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.  \n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1PyKBEVl5jwQfB0I0P2kG8nTGQVZQdZEM\"  onerror=\"this.style.display='none'\" /><br><br>\n",
    "\n",
    "#### GRU\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1467jVFRYbw1DYvVKeSyzGWLRmtlqpy8z\"  onerror=\"this.style.display='none'\" style=\"width: 700px;\"/><br><br>\n",
    "The GRU operates using a reset gate (r) and an update gate (z). The candidate state is created by using the previous hidden state and the current input. It is the reset gate that determines how the previous hidden state affects the candidate state. The newly created candidate state and the previous hidden state create a new hidden state, in which the update gate plays a role in balancing the two.\n",
    "\n",
    "#### LSTM vs GRU\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1lzGTsIYvPWKNF-XaTevMaaZvjfgp9G35\"  onerror=\"this.style.display='none'\" style=\"width: 600px;\"/><br><br>\n",
    "\n",
    "| <center>LSTM</center> | <center>GRU</center>  |\n",
    "|:--------|--------|\n",
    "| LSTM has 3 gates (forget, input, output) | GRU has 2 gates (reset, update) |\n",
    "| There is an internal memory (cell state) | There is no cell state and only hidden state exists |\n",
    "| When making output, another non-linearity is applied | There is no additional non-linearity when making output  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "PpL3bajyDnyy"
   },
   "outputs": [],
   "source": [
    "# 2 points\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # layer_dim과 batch_size는 1로 설정\n",
    "        self.layer_dim = 1\n",
    "        self.batch_size = 1\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "\n",
    "        # gru\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        #############\n",
    "        # initialize the linear layers and sigmoid function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.update_layer_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.update_layer_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.reset_layer_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.reset_layer_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.candidate_layer_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.candidate_layer_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        #############\n",
    "\n",
    "    def forward(self, input, hn):\n",
    "        #############\n",
    "        # set h_(n-1) and x_n from the given input and hn values\n",
    "        hn_1 = hn\n",
    "        xn = self.embedding(input)\n",
    "        \n",
    "        # calculate z(update gate), r(reset gate), and candidate hidden state of current time step\n",
    "        zn = self.sigmoid(self.update_layer_x(xn[:,0,:]) + self.update_layer_h(hn_1[0,:,:]))\n",
    "        rn = self.sigmoid(self.reset_layer_x(xn[:,0,:]) + self.reset_layer_h(hn_1[0,:,:]))\n",
    "        hcn = torch.tanh(self.candidate_layer_x(xn[:,0,:]) + self.candidate_layer_h(hn_1[0,:,:]) * rn)\n",
    "        \n",
    "        # calculate the hidden state and output of the current time step\n",
    "        hn = ((1 - zn) * hcn + zn * hn_1[0,:,:]).unsqueeze(0)\n",
    "        output = hn\n",
    "        #############\n",
    "        return output, hn\n",
    "\n",
    "    def initHidden(self):\n",
    "        # The size of h0 should be (layer_dim, batch_size, hidden_dim)\n",
    "        #############\n",
    "        # initialize the hidden state to zero-tensor with given dimension\n",
    "        if torch.cuda.is_available():  # if environment supports GPU\n",
    "            h0 = torch.autograd.Variable(torch.zeros(self.layer_dim, self.batch_size, self.hidden_dim)).cuda()\n",
    "        else:  # if environment does not support GPU\n",
    "            h0 = torch.autograd.Variable(torch.zeros(self.layer_dim, self.batch_size, self.hidden_dim))\n",
    "        #############\n",
    "        return h0\n",
    "    \n",
    "hidden_dim = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGjPPHD7Dnyy"
   },
   "source": [
    "#### Decoder\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1Rm_LlpEolCvPuzPWEFOZ-zdTfsgMbtu-\"  onerror=\"this.style.display='none'\" /><br><br>\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder, that single vector carries the burden of encoding the entire sentence. Attention allows the decoder network to \"focus\" on a specific part of\n",
    "the encoder's outputs for every step and thus help the decoder choose the right output words. \n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=18hsS8PAA7I3QaN9oOebfnMGAMhR-6EID\"  onerror=\"this.style.display='none'\" style=\"width: 170px;\"/><br><br>\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1F1Y92uLvGaI6s-ygyNKNox4ZGiZmTZ3g\"  onerror=\"this.style.display='none'\" style=\"width: 170px;\"/><br><br>\n",
    "\n",
    "The attention weights are calculated using an another feed-forward layer which inputs the decoder's input and hidden state. And the calculated attention weight is multiplied to the corresponding hidden state of the encoder, respectively. Note that to actually create and train this layer we have to choose a maximum sentence length. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1JEE23gtJf4XciJUXLt2R9lZtpRn8mYCN\"  onerror=\"this.style.display='none'\" /><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "NfWr22rFDnyz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2803\n"
     ]
    }
   ],
   "source": [
    "# 3 points\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # \n",
    "        self.layer_dim = 1\n",
    "        self.batch_size = 1\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_dim, self.hidden_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        # attention\n",
    "        # Note that the column of the attention weights is MAX_LENGTH\n",
    "        # Note that concatenation is used when \"attn\" and \"attn_combine\" are created\n",
    "        #############\n",
    "        # initialize the linear layers, softmax and ReLU function\n",
    "        # set the input size to hidden_dim * 2 considering concatenation\n",
    "        self.attn = nn.Linear(hidden_dim*2, MAX_LENGTH)  \n",
    "        self.attn_combine = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        #############\n",
    "        \n",
    "        # gru\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        #############\n",
    "        # initialize the linear layers and sigmoid function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.update_layer_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.update_layer_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.reset_layer_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.reset_layer_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.candidate_layer_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.candidate_layer_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        #############\n",
    "        \n",
    "        self.out = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, input, hn, encoder_outputs):\n",
    "        input = self.embedding(input).view(1, 1, -1)\n",
    "        input = self.dropout(input)\n",
    "        \n",
    "        # attention\n",
    "        # All specifications of the operations are described in the above figure (e.g. use ReLU)\n",
    "        # bmm is a operation which performs a batch matrix-matrix product\n",
    "        #############\n",
    "        # set h_(n-1) and x_n from the given input and hn values\n",
    "        hn_1 = hn\n",
    "        xn = input\n",
    "        \n",
    "        # set the attention input by concatenating the previous hidden state and the embedded input\n",
    "#         attn_weights = F.softmax(self.attn(torch.cat((input[0], hn_1[0]), 1)), dim=1)\n",
    "#         attn_input = torch.cat((hn_1, xn), dim=2)\n",
    "        attn_input = torch.cat((xn[0], hn_1[0]), 1)\n",
    "        # propagate to the attention linear layer and obtain attention weights by applying softmax\n",
    "        attn = self.attn(attn_input)\n",
    "        attn_weights = self.softmax(attn)\n",
    "        \n",
    "        # calculate attn_applied by batch matrix multiplication between attention weights and encoder outputs\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        # set the attention combine input by concatenating the attn_applied value and the transformed input\n",
    "        attn_combine_input = torch.cat((xn[0], attn_applied[0]), 1)\n",
    "        # propagate to the attention combine linear layer\n",
    "        attn_combined = self.attn_combine(attn_combine_input).unsqueeze(0)\n",
    "        # propagate to the ReLU function and obtain the attention output\n",
    "        attn_output = self.relu(attn_combined)\n",
    "        #############\n",
    "        \n",
    "        # gru\n",
    "        #############\n",
    "        # calculate z(update gate), r(reset gate), and candidate hidden state of current time step\n",
    "        zn = self.sigmoid(self.update_layer_x(attn_output[:,0,:]) + self.update_layer_h(hn_1[0,:,:]))\n",
    "        rn = self.sigmoid(self.reset_layer_x(attn_output[:,0,:]) + self.reset_layer_h(hn_1[0,:,:]))\n",
    "        hcn = torch.tanh(self.candidate_layer_x(attn_output[:,0,:]) + self.candidate_layer_h(hn_1[0,:,:]) * rn)\n",
    "        \n",
    "        # calculate the hidden state and output of the current time step\n",
    "        hn = ((1 - zn) * hcn + zn * hn_1[0,:,:]).unsqueeze(0)\n",
    "        output = hn\n",
    "        #############\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        return output, hn\n",
    "\n",
    "    def initHidden(self):\n",
    "        # The size of h0 should be (layer_dim, batch_size, hidden_dim)\n",
    "        #############\n",
    "        # initialize the hidden state to zero-tensor with given dimension\n",
    "        if torch.cuda.is_available():  # if environment supports GPU\n",
    "            h0 = torch.autograd.Variable(torch.zeros(self.layer_dim, self.batch_size, self.hidden_dim)).cuda()\n",
    "        else:  # if environment does not support GPU\n",
    "            h0 = torch.autograd.Variable(torch.zeros(self.layer_dim, self.batch_size, self.hidden_dim))\n",
    "        #############\n",
    "        return h0\n",
    "    \n",
    "decoder = AttnDecoderRNN(hidden_dim, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "print(output_lang.n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg2utJ-1Dnyz"
   },
   "source": [
    "### 3. Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "KE-npWCODnyz"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate=0.01\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMr9RcDBDnyz"
   },
   "source": [
    "### 4. Write the evaluation code [2 points]\n",
    "\n",
    "- Using the trained model, display the translated output given input sentence.\n",
    "- max len < translated output길이 이면 강제로 중단, decoder가 EOS를 예측하면 문장 생성 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.index2word[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "UO3UzfFCDnyz"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        #############\n",
    "        # initialize the hidden state of encoder and decoder\n",
    "        en_hn = encoder.initHidden()\n",
    "        de_hn = decoder.initHidden()\n",
    "        #############\n",
    "        \n",
    "        encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_dim, device=device)\n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoded_words = []\n",
    "        \n",
    "        #############\n",
    "        # propagate every input word and hidden state to the encoder and obtain encoder outputs\n",
    "        for i in range(input_length):\n",
    "            en_output, en_hn = encoder(input_tensor[i].unsqueeze(0).cuda(), en_hn)\n",
    "            encoder_outputs[i] = en_output[0]\n",
    "        # propagate the encoder output and the hidden state to the decoder and obtain the translated output\n",
    "        while True:\n",
    "            # break the loop when length of decoded words exceeds the max length\n",
    "            if len(decoded_words) > MAX_LENGTH:\n",
    "                break\n",
    "            decoder_output, de_hn = decoder(decoder_input, de_hn, encoder_outputs)\n",
    "            # break the loop when \"EOS\" is predicted as an output character of current time step\n",
    "            if decoder_output[0].argmax().item() == 1:\n",
    "                break\n",
    "            # concatenate the predicted word to the output string and reset the decoder input based on current decoder output\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[decoder_output[0].argmax().item()])\n",
    "                decoder_input = decoder_output.argmax().unsqueeze(0)\n",
    "        #############\n",
    "\n",
    "        return decoded_words\n",
    "    \n",
    "def evaluateRandomly():\n",
    "    pair = random.choice(pairs)\n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7wNENhXDnyz"
   },
   "source": [
    "### 5 . Write the code to train the model [3 points]\n",
    "\n",
    "- During training, use the `Teacher forcing` concept in addition to a naive approach.\n",
    "    - In other words, instead of using the decoder's guess as the next input, the real target outputs are also used sometimes. This shows faster convergence.\n",
    "- Plot the training loss curve.\n",
    "- Show the result using $evaluateRandomly()$ function. Below is an example.\n",
    "*************************************************************\n",
    "    > il est en train de peindre un tableau . (input)\n",
    "    = he is painting a picture . (target)\n",
    "    < he is painting a picture . (output)\n",
    "*************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* iter1000 *************************\n",
      "loss 11.0851\n",
      "> c est un acteur .\n",
      "= he is an actor .\n",
      "< you re very .\n",
      "\n",
      "************************* iter2000 *************************\n",
      "loss 19.2924\n",
      "> il s affaire aux preparatifs du voyage .\n",
      "= he is busy preparing for the trip .\n",
      "< he is a good .\n",
      "\n",
      "************************* iter3000 *************************\n",
      "loss 27.7523\n",
      "> je suis remue .\n",
      "= i m shaken .\n",
      "< i m a .\n",
      "\n",
      "************************* iter4000 *************************\n",
      "loss 20.0283\n",
      "> tu souffres n est ce pas ?\n",
      "= you re in pain aren t you ?\n",
      "< you re not as as as as as as as as\n",
      "\n",
      "************************* iter5000 *************************\n",
      "loss 31.6984\n",
      "> vous etes tres curieux .\n",
      "= you re very curious .\n",
      "< you re very brave .\n",
      "\n",
      "************************* iter6000 *************************\n",
      "loss 13.1687\n",
      "> vous etes sympa .\n",
      "= you re nice .\n",
      "< you re a .\n",
      "\n",
      "************************* iter7000 *************************\n",
      "loss 10.0751\n",
      "> je suis votre s ur .\n",
      "= i m your sister .\n",
      "< i m going to do that .\n",
      "\n",
      "************************* iter8000 *************************\n",
      "loss 37.6781\n",
      "> elle est d une humeur massacrante .\n",
      "= she is in an awful mood .\n",
      "< she s a bit young guy .\n",
      "\n",
      "************************* iter9000 *************************\n",
      "loss 8.5603\n",
      "> c est toi le professeur .\n",
      "= you re the teacher .\n",
      "< he s the one .\n",
      "\n",
      "************************* iter10000 *************************\n",
      "loss 6.4089\n",
      "> je ne suis pas fatiguee du tout .\n",
      "= i m not at all tired .\n",
      "< i m not good at this .\n",
      "\n",
      "************************* iter11000 *************************\n",
      "loss 8.0539\n",
      "> je vais y songer .\n",
      "= i m going to sleep on it .\n",
      "< i m going to do some .\n",
      "\n",
      "************************* iter12000 *************************\n",
      "loss 6.1104\n",
      "> je me sens triste a cause de ca .\n",
      "= i am feeling sad about it .\n",
      "< i m very hungry .\n",
      "\n",
      "************************* iter13000 *************************\n",
      "loss 10.9988\n",
      "> mon poids me preoccupe .\n",
      "= i m worried about my weight .\n",
      "< i m very much .\n",
      "\n",
      "************************* iter14000 *************************\n",
      "loss 4.9761\n",
      "> vous n aidez pas beaucoup .\n",
      "= you re not helping much .\n",
      "< you re not good at this .\n",
      "\n",
      "************************* iter15000 *************************\n",
      "loss 6.7629\n",
      "> ils militent contre les violences aux animaux .\n",
      "= they re against animal abuse .\n",
      "< they re going to eat this .\n",
      "\n",
      "************************* iter16000 *************************\n",
      "loss 7.4682\n",
      "> je suis laid .\n",
      "= i m ugly .\n",
      "< i m curious .\n",
      "\n",
      "************************* iter17000 *************************\n",
      "loss 9.8267\n",
      "> vous etes suffisante .\n",
      "= you re conceited .\n",
      "< you re powerful .\n",
      "\n",
      "************************* iter18000 *************************\n",
      "loss 5.6810\n",
      "> je suis enchante de vous rencontrer .\n",
      "= i m delighted to meet you .\n",
      "< i m glad to see you .\n",
      "\n",
      "************************* iter19000 *************************\n",
      "loss 5.7844\n",
      "> elle a une bonne nature .\n",
      "= she is good natured .\n",
      "< she is a bit late .\n",
      "\n",
      "************************* iter20000 *************************\n",
      "loss 9.8428\n",
      "> je ne dors pas bien .\n",
      "= i m not sleeping well .\n",
      "< i m not patient .\n",
      "\n",
      "************************* iter21000 *************************\n",
      "loss 0.6011\n",
      "> je suis trop vieux pour aller en allemagne .\n",
      "= i m too old to go to germany .\n",
      "< i m too old for you .\n",
      "\n",
      "************************* iter22000 *************************\n",
      "loss 12.2577\n",
      "> ils ne me pretent pas attention .\n",
      "= they re ignoring me .\n",
      "< they re not dead yet .\n",
      "\n",
      "************************* iter23000 *************************\n",
      "loss 3.3595\n",
      "> je vais me marier .\n",
      "= i m getting married .\n",
      "< i m going to be your teacher .\n",
      "\n",
      "************************* iter24000 *************************\n",
      "loss 12.1119\n",
      "> nous sommes satisfaites .\n",
      "= we re contented .\n",
      "< we re in luck .\n",
      "\n",
      "************************* iter25000 *************************\n",
      "loss 1.3898\n",
      "> tu es mon amie .\n",
      "= you are my friend .\n",
      "< you re my friend .\n",
      "\n",
      "************************* iter26000 *************************\n",
      "loss 6.4329\n",
      "> tu me fais marcher .\n",
      "= you re pulling my leg .\n",
      "< you re preaching to the choir .\n",
      "\n",
      "************************* iter27000 *************************\n",
      "loss 3.1403\n",
      "> elle est vraiment intelligente n est ce pas ?\n",
      "= she s really smart isn t she ?\n",
      "< she s very religious aren t you ?\n",
      "\n",
      "************************* iter28000 *************************\n",
      "loss 1.7141\n",
      "> je suis fatigue de boston .\n",
      "= i m tired of boston .\n",
      "< i m tired of course .\n",
      "\n",
      "************************* iter29000 *************************\n",
      "loss 4.0236\n",
      "> je n en suis pas si sur !\n",
      "= i m not so sure .\n",
      "< i m not that worried .\n",
      "\n",
      "************************* iter30000 *************************\n",
      "loss 6.6232\n",
      "> il a tendance a oublier .\n",
      "= he is apt to forget .\n",
      "< he is used to the food .\n",
      "\n",
      "************************* iter31000 *************************\n",
      "loss 21.0607\n",
      "> nous enquetons sur le meurtre de tom jackson .\n",
      "= we re investigating the murder of tom jackson .\n",
      "< we are going to climb that car .\n",
      "\n",
      "************************* iter32000 *************************\n",
      "loss 4.1546\n",
      "> je ne suis pas si veinard .\n",
      "= i m not so lucky .\n",
      "< i m not so lucky .\n",
      "\n",
      "************************* iter33000 *************************\n",
      "loss 6.1640\n",
      "> nous sommes presque a court de sucre .\n",
      "= we re almost out of sugar .\n",
      "< we re almost out of time .\n",
      "\n",
      "************************* iter34000 *************************\n",
      "loss 9.7027\n",
      "> vous etes tres occupee .\n",
      "= you re very busy .\n",
      "< you re very busy .\n",
      "\n",
      "************************* iter35000 *************************\n",
      "loss 38.2948\n",
      "> je suis amie avec de nombreux flics .\n",
      "= i m friends with a lot of cops .\n",
      "< i m worried with tom s house .\n",
      "\n",
      "************************* iter36000 *************************\n",
      "loss 3.3925\n",
      "> vous etes l enseignant .\n",
      "= you re the teacher .\n",
      "< you re the teacher .\n",
      "\n",
      "************************* iter37000 *************************\n",
      "loss 5.2674\n",
      "> vous etes fort emotif .\n",
      "= you re very emotional .\n",
      "< you re very rude .\n",
      "\n",
      "************************* iter38000 *************************\n",
      "loss 14.8503\n",
      "> tu es beau .\n",
      "= you are beautiful .\n",
      "< you re beautiful .\n",
      "\n",
      "************************* iter39000 *************************\n",
      "loss 9.7706\n",
      "> je suis heureux de vous avoir engages .\n",
      "= i m glad i hired you .\n",
      "< i m glad to see you .\n",
      "\n",
      "************************* iter40000 *************************\n",
      "loss 17.5348\n",
      "> je suis trois ans plus jeune que toi .\n",
      "= i m three years younger than you .\n",
      "< i m three years younger than you .\n",
      "\n",
      "************************* iter41000 *************************\n",
      "loss 0.3925\n",
      "> je suis contente que tu sois la .\n",
      "= i m glad you re here .\n",
      "< i m glad you re here .\n",
      "\n",
      "************************* iter42000 *************************\n",
      "loss 1.9941\n",
      "> je suis plus intelligent que toi .\n",
      "= i m smarter than you .\n",
      "< i m smarter than you .\n",
      "\n",
      "************************* iter43000 *************************\n",
      "loss 3.7995\n",
      "> il est connu dans le pays entier .\n",
      "= he is known to the entire country .\n",
      "< he is good at singing the best .\n",
      "\n",
      "************************* iter44000 *************************\n",
      "loss 13.4942\n",
      "> il a peur de mourir .\n",
      "= he is afraid that he will die .\n",
      "< he s afraid i have to die .\n",
      "\n",
      "************************* iter45000 *************************\n",
      "loss 32.6591\n",
      "> ils ne vont pas nous attraper .\n",
      "= they re not going to catch us .\n",
      "< they re not getting involved .\n",
      "\n",
      "************************* iter46000 *************************\n",
      "loss 1.7196\n",
      "> je suis humain .\n",
      "= i am human .\n",
      "< i m skinny .\n",
      "\n",
      "************************* iter47000 *************************\n",
      "loss 3.9222\n",
      "> c est un homme de famille noble .\n",
      "= he is a man of noble birth .\n",
      "< he is a man of character .\n",
      "\n",
      "************************* iter48000 *************************\n",
      "loss 11.9211\n",
      "> vous etes tres curieuses .\n",
      "= you re very curious .\n",
      "< you are very kind .\n",
      "\n",
      "************************* iter49000 *************************\n",
      "loss 12.8011\n",
      "> je suis tres reconnaissant pour votre aide .\n",
      "= i m very grateful for your help .\n",
      "< i m very grateful about your help .\n",
      "\n",
      "************************* iter50000 *************************\n",
      "loss 1.4010\n",
      "> nous n avons plus de vin .\n",
      "= we re out of wine .\n",
      "< we re not sure we re completely .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f69e095f410>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_iters = 50000\n",
    "print_every = 1000\n",
    "plot_every =100\n",
    "\n",
    "plot_losses = []\n",
    "print_loss_total = 0  # Reset every print_every\n",
    "plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "\n",
    "for iter in range(1, n_iters+1):\n",
    "    # Load data\n",
    "    training_pair = training_pairs[iter-1]\n",
    "    input_tensor = training_pair[0]\n",
    "    target_tensor = training_pair[1]\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    #############\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    #############\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = 0\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    #############\n",
    "    # initialize the hidden state of encoder and decoder\n",
    "    en_hn = encoder.initHidden()\n",
    "    de_hn = decoder.initHidden()\n",
    "    #############\n",
    "    \n",
    "    encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_dim, device=device)\n",
    "    \n",
    "    #############\n",
    "    # forward each word of the input and the previous hidden state to the encoder and obtain the encoder outputs\n",
    "    for i in range(input_length):\n",
    "        en_output, en_hn = encoder(input_tensor[i].unsqueeze(0), en_hn)\n",
    "        encoder_outputs[i] = en_output[0]\n",
    "    #############\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    \n",
    "    #############\n",
    "    # forward each input word, previous hidden state, and the encoder outputs to the decoder and obtain decoder outputs\n",
    "    decoder_output = torch.tensor([], device=device).squeeze()\n",
    "    for i in range(target_length):\n",
    "        decoder_output, de_hn = decoder(decoder_input, de_hn, encoder_outputs)\n",
    "        decoder_input = target_tensor[i]\n",
    "        loss += criterion(decoder_output, target_tensor[i].to(device))\n",
    "    #############\n",
    "\n",
    "    # Backward pass\n",
    "    #############\n",
    "    loss.backward()\n",
    "    #############\n",
    "\n",
    "    # Updating parameters\n",
    "    #############\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    #############\n",
    "    \n",
    "    print_loss_total += loss.item() / target_length\n",
    "    plot_loss_total += loss.item() / target_length\n",
    "    \n",
    "    if iter % print_every == 0:\n",
    "        print('*'*25, 'iter%d'%iter, '*'*25)\n",
    "        print('loss %.4f'%loss)\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        evaluateRandomly()\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "\n",
    "#################################################\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> il est joueur .\n",
      "= he s a gambler .\n",
      "< he is a gambler .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> tu es un etudiant .\n",
      "= you are a student .\n",
      "< you are a student .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je suis chez moi tom .\n",
      "= i m home tom .\n",
      "< i am home tom .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> tu es le dernier espoir de l humanite .\n",
      "= you re the last hope for humanity .\n",
      "< you re the last hope for humanity .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "- loss값을 100번의 iteration마다 구한 평균 loss를 plot한 결과, 첫 epoch부터 10000 epoch까지 빠르게 감소하고, 이후 1.0 정도의 값에서 수렴함을 확인할 수 있었습니다. 이를 통해 attention seq2seq network가 epoch가 경과함에 따라 loss의 수렴이 이뤄지며 제대로 학습되고 있다는 것을 알 수 있습니다. \n",
    "- Attention 기법을 사용한 seq2seq network는 문장 sequence 내의 단어 별 encoder output에 대해 attention 가중치를 두어, 각각의 decoder hidden state에 attention weight을 반영하여 decoder의 output 계산에 반영합니다. 따라서 seq2seq network는 attention을 통해 문장 내 단어와 단어 사이의 관계를 더욱 잘 파악하며 학습하고, 그에 따라 번역된 문장을 더욱 잘 구성함을 확인할 수 있었습니다. \n",
    "- 한편, 1000 epoch마다 print된 번역 결과를 살펴보자면 epoch를 거듭할수록 생성되는 문장이 점차 target sentence와 일치하는 결과를 생성함을 확인할 수 있었습니다. 간혹 loss값이 크게 나타나거나 예측한 translated output이 부정확한 경우도 발생했지만, 그런 경우들 중 의미상으로 비슷한 문장들이 얻어지는 것을 특정 결과값들에서 확인할 수 있었습니다. 더 정확한 예측 결과를 얻기 위해서는 multi-layered seq2seq를 사용하여 layer와 parameter수를 늘리거나, training batch size를 늘려 효율적인 학습이 가능하도록 하는 방식 등을 활용할 수 있을 것입니다. \n",
    "- 학습이 완료된 모델에 대해 evaluateRandomly 함수를 실행하여 target sentence와 translated output이 거의 일치함을 확인할 수 있었습니다.다. 앞서 문자열 가공 과정에서 단축어를 설정해 주었기 때문에 사실상 첫 번째와 세번째 결과도 같은 문장을 의미합니다. 이를 통해 현재 학습된 모델은 제공된 데이터셋 내에서 임의로 생성된 프랑스어 문장에 대하여 높은 수준의 정확도를 가지고 영어로 번역된 문장을 만들어낸다는 사실을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrccVZ1gDny0"
   },
   "source": [
    "### *References*\n",
    "[1] [practical pytorch](https://github.com/spro/practical-pytorch)(https://github.com/spro/practical-pytorch)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EEE4423_lab11_Seq2Seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Full on Python 3.7 (GPU)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
