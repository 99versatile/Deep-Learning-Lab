{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clIFh_guHNFv"
   },
   "source": [
    "> ### EEE4423: Deep Learning Lab\n",
    "\n",
    "# LAB \\#11: Character Generation using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un-_JnG1HNF1"
   },
   "source": [
    "<h4><div style=\"text-align: right\"> Due date: May 19, 2023. </div> <br>\n",
    "<div style=\"text-align: right\"> Please upload your file @ LearnUs by 9 AM in the form of [ID_Name_Lab11.ipynb]. </div></h4>\n",
    "\n",
    "### *Instructions:*\n",
    "- Write a program implementing a particular algorithm to solve a given problem.   \n",
    "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span> \n",
    "- Each team must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nats-XhJHNF2"
   },
   "source": [
    "<h2><span style=\"color:blue\">[2018142102] [Euijin Hong]</span> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DUNE2wXfHNF2",
    "outputId": "cf8804ce-9063-463d-988f-cd900bd149b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2023-05-14 07:41:49.065993\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "\u001b[33m  WARNING: The script unidecode is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed unidecode-1.3.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install unidecode --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J8vQvyjWHNF5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9OP9XM9HNF5"
   },
   "source": [
    "These sorts of generative models form the basis of machine translation, image captioning, question answering and more.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=16E7HG_dCyfTo9u9qrrhp2eClq6xK6-f_\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YQl92mwHNF6"
   },
   "source": [
    "### 1. Prepare data\n",
    "\n",
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymNU_-ZGHNF6"
   },
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=171lX3vxj60AQNScQi872BHx2Rz6J7-3J\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TFK9sT_1HNF6",
    "outputId": "1bbcf9b6-7367-4aba-ff59-7a3e6134441d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 4063\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./dataset-dllab/lab11/lose_yourself_eminem.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUyRw-C2HNF6"
   },
   "source": [
    "To make inputs out of this big string of data, we will be splitting it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6nPqv8tuHNF7",
    "outputId": "2a05a019-0267-43fd-9e6a-cbcf9c5ac4c3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\n",
      "The souls escaping, through this hole that its gaping\n",
      "This world is mine for the taking\n",
      "Make me king, as we move toward a, new world order\n",
      "A normal life is borin', but super stardom's close to post m\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScRzeDr8HNF9"
   },
   "source": [
    "Each chunk will be turned into a tensor by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TylqhpuyHNF9",
    "outputId": "9e4b9d7e-bea0-41a5-d853-caaa711be679",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n",
      "abcDEF is changed to  tensor([10, 11, 12, 39, 40, 41])\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "all_characters = string.printable\n",
    "print(all_characters)\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print('abcDEF is changed to ', char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1XvIwnaHNF9"
   },
   "source": [
    "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters *up to the last*, and the target will be all characters *from the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YfaPPbDMHNF-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inputs = char_tensor(chunk[:-1])\n",
    "    targets = char_tensor(chunk[1:])\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaQ88mGNHNF-"
   },
   "source": [
    "### 2. Build the LSTM model [4 points]\n",
    "\n",
    "#### [Diagram of LSTM]\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1baQ6Ffu-vDcXbOEBYGeLzhmfvaj4DGgW\" style=\"width: 800px;\"/>\n",
    "LSTM consists of cell state, hidden state and 3 gates that modify or use the cell state. The cell state is the key part of the LSTM and you can think that information \"flows\" in there. The operation of 3 gates are described in below.\n",
    "\n",
    "#### [Forget Gate]\n",
    "The forget gate determines which information in the cell state should be erased.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1sJisl5P0hggmvH4qrcYgSETFKdFdBSH_\" style=\"width: 600px;\"/>\n",
    "\n",
    "#### [Input Gate]\n",
    "First, the candidate cell state is created using the current input and the previous hidden state. And the input gate determines how much the candidate cell state is reflected to the cell state.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1Df-k5FORGH7PnXauYcb8qqUpY3Uot9A7\" style=\"width: 600px;\"/>\n",
    "\n",
    "#### [Output Gate]\n",
    "The output gate determines which elements should be extracted from the cell state to produce the output.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1JLCGPcrZLOYfjyJhMTvmfixHq5plFj8L\" style=\"width: 600px;\"/>\n",
    "\n",
    "The above expression is summarized as follows,\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1kGq8DwwzizuNcg6GF0GaP1DAu26FFlrB\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my4efNewHNF-"
   },
   "source": [
    "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one LSTM layer that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (encoder): Embedding(100, 100)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (forget_layer): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (input_layer): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (output_layer): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (c_state_layer): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        # lstm\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        #############\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # one-depth fully-connected layer in forget gate\n",
    "        self.forget_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # one-depth fully-connected layer in input gate\n",
    "        self.input_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # one-depth fully-connected layer in output gate\n",
    "        self.output_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # one-depth fully-connected layer in candidate cell state\n",
    "        self.c_state_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        #############\n",
    "        \n",
    "        self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, input, hn, cn):\n",
    "        #############\n",
    "        # iterate for number of LSTM layers\n",
    "        for n in range(n_layers):\n",
    "            # previous hn and cn are given as an input of a forward function\n",
    "            hn_1, cn_1 = hn, cn\n",
    "            \n",
    "            # for initial LSTM layer, input is the input of the multi-layered LSTM\n",
    "            if n == 0:\n",
    "                # convert the input into same shape as hidden input, xn size: [1, 1, 100]\n",
    "                xn = self.encoder(input)\n",
    "            # for consequtive LSTM layer, input is the output of the previous LSTM layer\n",
    "            else:\n",
    "                # convert the previous ouptut into same shape as hidden input, xn size: [1, 1, 100]\n",
    "                xn = self.encoder(output.argmax().unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "            # add encoded input and hidden input to form a gate input (h_(n-1), x_t), size: [1, 1, 100]\n",
    "            gate_input = torch.add(hn_1, xn)\n",
    "            \n",
    "            # calculate f_n\n",
    "            f_n = self.sigmoid(self.forget_layer(gate_input))\n",
    "            # calculate i_n\n",
    "            i_n = self.sigmoid(self.input_layer(gate_input))\n",
    "            # calculate candidate cell state C^~_n(= g)\n",
    "            g = torch.tanh(self.c_state_layer(gate_input))\n",
    "            # calculate o_n\n",
    "            o_n = self.sigmoid(self.output_layer(gate_input))\n",
    "            \n",
    "            # calculate C_n \n",
    "            cn = f_n * cn_1 + i_n * g\n",
    "            # calculate h_n\n",
    "            hn = o_n * torch.tanh(cn)\n",
    "            \n",
    "            # obtain output by propagating decoding layer h_n, size: [1, 1, 100]\n",
    "            output = self.decoder(hn)\n",
    "        #############\n",
    "            \n",
    "        return output, hn, cn\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # The size of h0, c0 should be (layer_dim, batch_size, hidden_dim)\n",
    "        #############\n",
    "        # initialzing the cell state and input to the hidden layer to zero, both size: [1, 1, 100]\n",
    "        # batch size given as 1\n",
    "        if torch.cuda.is_available():  # if environment supports GPU\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim)).cuda()\n",
    "            c0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim)).cuda()\n",
    "        else:  # if environment does not support GPU\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim))\n",
    "            c0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim))\n",
    "        return h0, c0\n",
    "        #############\n",
    "    \n",
    "hidden_dim = 100\n",
    "n_layers = 1\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "model = LSTMModel(n_characters, hidden_dim, n_layers, n_characters)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qajoki2HNF_"
   },
   "source": [
    "### 3. Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xvm-picHHNF_"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 0.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5haXxzwOHNF_"
   },
   "source": [
    "### 4 . Write the character level generation code [4 points]\n",
    "\n",
    "- Generate a sentence with a length of $predict\\_len$, starting from a single character $prime\\_str$.\n",
    "- Example) evaluate(prime_str='Y', predict_len=20) -> You better let it go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JKkMfsh1HNF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str='W', predict_len=100):\n",
    "    # suppose prime_str is a single character\n",
    "    # and use greedy search to predict the next character\n",
    "\n",
    "    hn, cn = model.init_hidden()\n",
    "    predicted = str()\n",
    "    # initially add the prime_str character to the predicted string\n",
    "    predicted += prime_str\n",
    "    \n",
    "    for i in range(predict_len):\n",
    "        #############        \n",
    "        # prime_str converted to an input character index tensor\n",
    "        in_char_index = char_tensor(prime_str).unsqueeze(0).cuda()\n",
    "        # forwarding the model with given input character index, hn, and cn\n",
    "        output, hn, cn = model(in_char_index, hn, cn)\n",
    "        # obtain the predicted next character from a greedy search method\n",
    "        out_char_index = output[-1].argmax()\n",
    "        # concatenate the next character to the predicted string\n",
    "        predicted += all_characters[out_char_index]\n",
    "        # update the prime_str to the latest character added in the predicted string\n",
    "        prime_str = predicted[-1]\n",
    "        #############\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt4VFJd5HNF_"
   },
   "source": [
    "### 5 . Write the code to train the model [2 points]\n",
    "\n",
    "- Plot the training loss curve.\n",
    "- Print the output sentence with a length of 100, using $evaluate()$ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "LC0xsnlRHNF_",
    "outputId": "069881bd-f136-4501-fcbc-e8bb0bf3afbd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* epoch100 *************************\n",
      "loss 361.4271\n",
      "I mout one the the the the the the the the the the the the the the the the the the the the the the th \n",
      "\n",
      "************************* epoch200 *************************\n",
      "loss 358.5416\n",
      "I can't the moment one the moment one the moment one the moment one the moment one the moment one the \n",
      "\n",
      "************************* epoch300 *************************\n",
      "loss 335.5292\n",
      "I mama dand it go\n",
      "You better never let it go\n",
      "You better never let it go\n",
      "You better never let it go\n",
      "Yo \n",
      "\n",
      "************************* epoch400 *************************\n",
      "loss 301.8921\n",
      "I moment\n",
      "You better never let it go\n",
      "You better never let it go\n",
      "You better never let it go\n",
      "You better  \n",
      "\n",
      "************************* epoch500 *************************\n",
      "loss 184.0570\n",
      "I moment\n",
      "You own it, you better never let it go\n",
      "You own it, you better never let it go\n",
      "You own it, yo \n",
      "\n",
      "************************* epoch600 *************************\n",
      "loss 253.9429\n",
      "I move, he's grows here goes Rabbit, he knows his opportunity comes once in a lifetime you better nev \n",
      "\n",
      "************************* epoch700 *************************\n",
      "loss 216.0641\n",
      "I now\n",
      "This opportunity comes once in a lifetime you better\n",
      "You better never let it go\n",
      "You only get on \n",
      "\n",
      "************************* epoch800 *************************\n",
      "loss 129.3167\n",
      "I mover there and souls capture that its go move to to fore the next shows, he nose yourself in the m \n",
      "\n",
      "************************* epoch900 *************************\n",
      "loss 170.4731\n",
      "I wan here goes so low\n",
      "This opportunity comes once in a lifetime you better\n",
      "You better lose yourself  \n",
      "\n",
      "************************* epoch1000 *************************\n",
      "loss 47.7578\n",
      "I move it, he knows his world one shot, do not miss your chance to blow\n",
      "This opportunity comes once i \n",
      "\n",
      "************************* epoch1100 *************************\n",
      "loss 107.8363\n",
      "I wan he moment\n",
      "You own it, you better never let it go\n",
      "You only get one shot, do not miss your chance \n",
      "\n",
      "************************* epoch1200 *************************\n",
      "loss 58.2808\n",
      "I wan he moment\n",
      "You own it, you better never let it go\n",
      "You only get one shot, do not miss your chance \n",
      "\n",
      "************************* epoch1300 *************************\n",
      "loss 45.5687\n",
      "I got\n",
      "To opportunity comes once in a lifetime you better\n",
      "You better lose yourself in the music, the m \n",
      "\n",
      "************************* epoch1400 *************************\n",
      "loss 12.2119\n",
      "I got\n",
      "You better lose yourself in the music, the moment\n",
      "You own it, you better never let it go\n",
      "You on \n",
      "\n",
      "************************* epoch1500 *************************\n",
      "loss 38.3523\n",
      "I got\n",
      "He been chewed up and spit out and booed off stage\n",
      "But I kept rhymin' and stepwritin' the next  \n",
      "\n",
      "************************* epoch1600 *************************\n",
      "loss 16.9852\n",
      "I got\n",
      "To formulate a plot fore I end up in jail or shot\n",
      "Feer shot\n",
      "Feet fail me not miss your chance t \n",
      "\n",
      "************************* epoch1700 *************************\n",
      "loss 32.1396\n",
      "I got\n",
      "You better lose yourself in the music, the moment\n",
      "You own it, you better never let it go\n",
      "You on \n",
      "\n",
      "************************* epoch1800 *************************\n",
      "loss 18.2474\n",
      "I got\n",
      "You better lose yourself in the music, the moment\n",
      "You own it, you better never let it go\n",
      "You on \n",
      "\n",
      "************************* epoch1900 *************************\n",
      "loss 33.0148\n",
      "I fold in Sale comes once in a lifetime you better\n",
      "You better lose yourself in the music, the moment\n",
      " \n",
      "\n",
      "************************* epoch2000 *************************\n",
      "loss 15.8835\n",
      "I got\n",
      "You better lose yourself in the music, the moment\n",
      "You own it, you better never let it go\n",
      "You on \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3e7a1b7490>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    #############\n",
    "    # initialzing the cell state and input to the hidden layer, size: [1, 1, 100]\n",
    "    hn, cn = model.init_hidden()\n",
    "    #############\n",
    "    # Load text\n",
    "    inputs, targets = random_training_set()\n",
    "    if inputs.size()[0] < 200: continue\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    #############\n",
    "    optimizer.zero_grad()\n",
    "    #############\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = 0\n",
    "    #############\n",
    "    # repeat the forward pass for every characters in an input string\n",
    "    for i in range(inputs.size()[0]):\n",
    "        output, hn, cn = model(inputs[i].unsqueeze(0).unsqueeze(0).cuda(), hn, cn)\n",
    "        # calculating the cross entropy loss between the predicted character and the target character\n",
    "        loss += criterion(output[-1], targets[i].unsqueeze(0).cuda())\n",
    "    #############\n",
    "    \n",
    "    # Backward pass\n",
    "    #############\n",
    "    loss.backward()\n",
    "    #############\n",
    "    \n",
    "    # Updating parameters\n",
    "    #############\n",
    "    optimizer.step()\n",
    "    #############\n",
    "    \n",
    "    loss_avg += loss.item() / chunk_len\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('*'*25, 'epoch%d'%epoch, '*'*25)\n",
    "        print('loss %.4f'%loss.item())\n",
    "        print(evaluate('I', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "\n",
    "#################################################\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "- 논문에서 주어진 것과 같이 cell state, hidden state에 해당하는 값들과, forget gate, input gate, output gate 연산들을 활용하여 LSTM 모델을 구현하였다. \n",
    "- training과 evaluation에 해당하는 부분은 input으로 들어오는 문자열에 대해 for 문을 통해 각각의 문자들을 순차적으로 입력해 주었으며, batch size는 1로 두었다. 거기에 더해 이전 output으로 생성된 cell state, hidden state값을 input으로 받아 직전 character prediction에 대한 정보를 바탕으로 학습할 수 있었다. \n",
    "- 총 2000번의 epoch동안 Eminem의 'Lose Yourself'로부터 랜덤하게 생성된 문자열에 대해 학습을 시켰으며, epoch을 거듭할수록 각각의 gate들에 연결되어 있는 layer들은 input에 대한 최적의 cell state, hidden state가 생성되도록 학습되었다. \n",
    "- 이는 epoch가 거듭할수록 predicted string과 target string 사이의 loss 값이 감소함을 통해 정량적으로 확인할 수 있는데, 초기 100번째 epoch에서는 361.4271의 loss값을 보인 반면, 최종적으로 2000번째 epoch에서는 15.8835의 loss로 수렴하였다. \n",
    "- 실제로 예측되는 string의 값을 확인해보면, 초기 epoch에서는 같은 문자열이 여러 번 반복되는 등 실제 target string인 Eminem의 가사와는 거리가 멀었지만, 최종적으로 얻은 predicted string을 보면 target string의 일부분과 정확히 일치함을 확인할 수 있었다. 이를 통해 주어진 문자열에 대한 학습이 매우 잘 이뤄졌음을 정성적으로 확인할 수 있었다. \n",
    "- 이를 통해 길이 200의 긴 문자열을 대상으로 학습을 시키고, 길이 100짜리 예측된 긴 문자열을 출력시키는 task에서는 LSTM의 강점이 드러남을 확인할 수 있었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCGRgEuZHNF_"
   },
   "source": [
    "### *References*\n",
    "[1] [practical pytorch](https://github.com/spro/practical-pytorch)(https://github.com/spro/practical-pytorch)\n",
    "\n",
    "[2] [CS 231n](http://cs231n.stanford.edu/syllabus.html)(http://cs231n.stanford.edu/syllabus.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EEE4423_lab10_Character Generation using LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Full on Python 3.6 (GPU)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
